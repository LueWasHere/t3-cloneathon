from flask import Flask, render_template, request, jsonify, send_from_directory
import random
import time
import os
import sqlite3
import re

app = Flask(__name__)

# --- Database Configuration ---
DB_DIR = 'db'
DB_PATH = os.path.join(DB_DIR, 'models.db')

def check_db_exists():
    """Checks if the database file exists and provides instructions if not."""
    if not os.path.exists(DB_PATH):
        print("="*60)
        print(f"FATAL ERROR: Database file not found at '{DB_PATH}'")
        print("This application requires a pre-existing database.")
        print("\nPlease create it by running the following command from your")
        print("project's root directory:")
        print("\n    sqlite3 db/models.db < create_db.sql\n")
        print("="*60)
        exit(1) # Stop the application if DB is missing.
    print(f"Database found at '{DB_PATH}'. Starting application.")


def get_db_conn():
    """Establishes a connection to the SQLite database."""
    conn = sqlite3.connect(DB_PATH)
    conn.row_factory = sqlite3.Row
    return conn

# --- End Database ---


# Sample responses for different models (keys should match model_name in DB)
SAMPLE_RESPONSES = {
    'gpt-4o-mini': [
        "I'm GPT-4o Mini! I'm fast, affordable, and nearly as smart as my bigger sibling. How can I help?",
        "Hello! I'm running on GPT-4o Mini. What would you like to know or discuss?"
    ],
    'gpt-4o': [
        "Hello! I'm GPT-4o from OpenAI. I'm designed to be helpful, creative, and accurate. What can I do for you?",
        "GPT-4o here! I'm optimized for a wide range of tasks including vision and reasoning. What would you like to explore?"
    ],
    'claude-3.5-sonnet-20240620': [
        "Hello from Claude 3.5 Sonnet! I'm Anthropic's latest model, offering top-tier intelligence at high speed. What can I help you build?",
        "I'm Claude 3.5 Sonnet, and I aim to be helpful, harmless, and honest. What can I assist you with?",
    ],
    'claude-3-opus-20240229': [
        "Hello from Claude 3 Opus! I am Anthropic's most capable model for highly complex tasks. How can I assist you?",
        "Claude 3 Opus here. I offer top-level performance on highly complex challenges. What can I do for you?",
    ],
    'gemini-1.5-pro': [
        "I'm Gemini 1.5 Pro, designed for complex reasoning tasks with a massive context window. What can I help you with?",
        "Gemini 1.5 Pro at your service! I'm optimized for in-depth analysis and complex problem-solving."
    ],
    'gemini-1.5-flash': [
        "I'm Gemini 1.5 Flash! I'm designed to be fast and efficient, with a huge context window. How can I help you today?",
        "Hello! I'm running on Gemini 1.5 Flash. What would you like to know or discuss?"
    ],
    'deepseek-coder': [
        "DeepSeek Coder at your service! I am specialized in code generation and understanding. How can I help with your programming tasks?",
        "Hello! I'm DeepSeek Coder. Ask me anything about code, algorithms, or software development.",
    ],
    'meta-llama/Llama-3.1-70B-Instruct': [
        "Hello! I'm Llama 3.1 70B, a powerful open model from Meta. How can I help you today?",
        "Llama 3.1 70B here! I'm great for a wide variety of tasks. What's on your mind?",
    ]
}

def get_ai_response(message, model):
    # This function remains the same, it just gets called with DB model names
    time.sleep(random.uniform(0.5, 1.5))
    message_lower = message.lower()
    if 'hello' in message_lower or 'hi' in message_lower:
        return random.choice(SAMPLE_RESPONSES.get(model, [f"Hello from {model}! How can I help you?"]))
    elif 'how does ai work' in message_lower:
        return f"AI works by using algorithms to find patterns in data. This allows it to make predictions and generate new content. It's a broad field, but that's the core idea!\n\n*Response generated by {model}*"
    elif 'black holes' in message_lower:
        return f"Yes, black holes are definitely real! They are regions in space where gravity is so strong that nothing, not even light, can escape.\n\n*Response generated by {model}*"
    elif 'strawberry' in message_lower and ('r' in message_lower or 'letter' in message_lower):
        return f"There are three 'r's in the word 'strawberry'.\n\n*Response generated by {model}*"
    elif 'meaning of life' in message_lower:
        return f"That's a deep question! There's no single answer, but many find meaning in relationships, personal growth, and contributing to something bigger than themselves.\n\n*Response generated by {model}*"
    else:
        return f"That's an interesting question! As {model}, I'm processing your request. In a real application, I would provide a detailed answer here."


def format_model_data(row):
    """Formats a database row into a dictionary for the frontend."""
    provider_name = row['provider_name']
    model_name = row['model_name']

    provider_key_map = {
        'OpenAI': 'openai',
        'Anthropic': 'claude',
        'Google': 'gemini',
        'xAI': 'grok',
        'DeepSeek': 'deepseek',
    }
    provider_key = provider_key_map.get(provider_name, provider_name.lower())
    if provider_name == 'Together.ai' and 'meta-llama' in model_name:
        provider_key = 'meta'

    # Create user-friendly display names
    main_name, sub_name = model_name, ''
    # A simple regex to split common model names for display
    match = re.match(r'([a-zA-Z0-9\._/]+-?)([\d\.]+[a-zA-Z]*-?instruct|[\d\.]+-?pro|[\d\.]+-?flash|[\d\.]+-?sonnet|[\d\.]+-?opus|[\d\.]+-?haiku|o-?mini|turbo|mini)?', model_name, re.IGNORECASE)
    if match and match.groups()[1]: # If we found a recognizable suffix
        main_name_raw = match.groups()[0].strip('-').replace('meta-llama/Llama', 'Llama').replace('claude-','Claude ')
        sub_name_raw = match.groups()[1].strip('-').replace('-Instruct', '')
        main_name = ' '.join(p.capitalize() for p in main_name_raw.replace('-', ' ').split())
        sub_name = ' '.join(p.capitalize() for p in sub_name_raw.replace('-', ' ').split())
        if 'Gpt-4o' in main_name: main_name = 'GPT-4o'
    else: # Fallback for names that don't match the pattern
        main_name = model_name

    is_premium = False
    premium_icon = None
    price = row['usd_per_million_input_tokens']
    if price is not None and price > 2.5: # Heuristic for 'premium'
        is_premium = True
    
    if is_premium:
        if 'opus' in model_name or '405b' in model_name or 'gpt-4o' == model_name:
            premium_icon = 'gem'
        elif 'pro' in model_name or 'turbo' in model_name or '70b' in model_name:
            premium_icon = 'flask'
        elif row['reasoning_enabled']:
            premium_icon = 'key'

    capabilities = {
        'vision': bool(row['supports_images_input']),
        'reasoning': bool(row['reasoning_enabled']),
        'coding': 'coder' in model_name or 'codex' in model_name,
        'web': 'grok' in model_name, # Simple heuristic
        'docs': bool(row['supports_pdfs_input']),
    }

    return {
        'name': model_name,
        'provider': provider_key,
        'displayNameMain': main_name,
        'displayNameSub': sub_name,
        'subtitle': row['notes'],
        'premium': is_premium,
        'premium_icon': premium_icon,
        'capabilities': capabilities
    }


@app.route('/')
def index():
    return render_template('index.html')

@app.route('/static/<path:filename>')
def static_files(filename):
    # This route is necessary for Flask to serve CSS and JS files
    # The path is relative to a 'static' directory which is a Flask convention
    return send_from_directory('static', filename)

@app.route('/chat', methods=['POST'])
def chat():
    try:
        data = request.get_json()
        message = data.get('message', '').strip()
        model = data.get('model', 'gpt-4o-mini')
        if not message: return jsonify({'error': 'Empty message'}), 400
        response = get_ai_response(message, model)
        return jsonify({'response': response})
    except Exception as e:
        print(f"Error in chat endpoint: {e}")
        return jsonify({'error': 'Internal server error'}), 500

@app.route('/models')
def get_models_data():
    conn = get_db_conn()
    try:
        db_models = conn.execute('SELECT * FROM models WHERE is_active = 1 ORDER BY provider_name, usd_per_million_input_tokens DESC').fetchall()
    except sqlite3.OperationalError as e:
        print(f"Error querying database: {e}")
        return jsonify({'error': f"Database query failed: {e}. Is the DB schema correct?"}), 500
    finally:
        conn.close()

    popular_model_names = ['gpt-4o', 'claude-3.5-sonnet-20240620', 'gemini-1.5-pro']
    
    popular_models = []
    all_other_models = []

    for row in db_models:
        formatted = format_model_data(row)
        if row['model_name'] in popular_model_names:
            popular_models.append(formatted)
        else:
            all_other_models.append(formatted)
    
    # Sort popular models by their original order in the list
    popular_models.sort(key=lambda m: popular_model_names.index(m['name']))

    return jsonify({
        'popular': popular_models,
        'all': all_other_models,
    })

if __name__ == '__main__':
    check_db_exists()
    # Flask convention is to put static files in a 'static' directory
    # and templates in a 'templates' directory.
    # We can create them if they don't exist for convenience.
    os.makedirs('static', exist_ok=True)
    # The index.html file should be in a 'templates' folder for Flask to find it.
    if not os.path.exists('templates'):
        os.makedirs('templates')
        print("\nNOTE: 'templates' directory created. Please move 'index.html' into it.\n")

    app.run(debug=True, host='0.0.0.0', port=5000)
